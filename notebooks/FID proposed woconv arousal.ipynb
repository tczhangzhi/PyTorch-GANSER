{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    NUM_EPOCHS = 300\n",
    "    NUM_CLASSES = 2\n",
    "    BATCH_SIZE = 64\n",
    "    TIMESTEP_NUM = 128\n",
    "    FOLD = 0\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "RECEIVED_PARAMS = {\n",
    "    \"c_lr\": 0.00001,\n",
    "    \"g_lr\": 0.00001,\n",
    "    \"d_lr\": 0.00001,\n",
    "    \"weight_gp\": 10.0,\n",
    "    \"weight_ssl\": 1.0,\n",
    "    \"weight_cls\": 10.0,\n",
    "    \"start_point\": 0,\n",
    "    \"delay_cls\": 1,\n",
    "    \"mixup\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET_BASE_DIR = Path('/home/username/Data/eeg-datasets')\n",
    "DATASET_FOLD_DIR = DATASET_BASE_DIR / 'DEAP'\n",
    "PREPROCESSED_EEG_DIR = DATASET_FOLD_DIR / 'data_preprocessed_python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessors import DEAPDataset, Sequence\n",
    "from preprocessors import BinaryLabel\n",
    "from preprocessors import Raw2TNCF, RemoveBaseline, TNCF2NCF, ChannelToLocation\n",
    "\n",
    "label_preprocessors = {'label': Sequence([BinaryLabel(positive='Arousal')])}\n",
    "feature_preprocessors = {\n",
    "    'feature':\n",
    "    Sequence([Raw2TNCF(),\n",
    "              RemoveBaseline(),\n",
    "              TNCF2NCF(),\n",
    "              ChannelToLocation()])\n",
    "}\n",
    "\n",
    "preprocessors_results = DEAPDataset(\n",
    "    PREPROCESSED_EEG_DIR, label_preprocessors,\n",
    "    feature_preprocessors)('./dataset/deap_binary_arousal_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, preprocessors_results, feature_key='feature', label_key='label'):\n",
    "        self.feature_key = feature_key\n",
    "        self.label_key = label_key\n",
    "\n",
    "        feature_list = []\n",
    "        label_list = []\n",
    "\n",
    "        for trail in preprocessors_results.keys():\n",
    "            feature = preprocessors_results[trail][feature_key]\n",
    "            feature_list.append(feature)\n",
    "            label = preprocessors_results[trail][label_key]\n",
    "            label_list.append(label)\n",
    "\n",
    "        feature_list = np.concatenate(feature_list, axis=0)\n",
    "        label_list = np.concatenate(label_list, axis=0)\n",
    "\n",
    "        self.feature_list = feature_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.from_numpy(self.feature_list[index]).float()\n",
    "        label = torch.tensor(self.label_list[index]).long()\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "\n",
    "def train_test_split(dataset,\n",
    "                     kfold_split_index_path='./cache/kfold_split_index.pkl',\n",
    "                     fold=0,\n",
    "                     n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     seed=520):\n",
    "    if not os.path.exists(kfold_split_index_path):\n",
    "        n_samples = len(dataset)\n",
    "        indices = np.arange(n_samples)\n",
    "        kfold = model_selection.StratifiedKFold(\n",
    "            n_splits=n_splits, shuffle=shuffle, random_state=seed)\n",
    "\n",
    "        index_dict = {}\n",
    "        for i, (train_index, test_index) in enumerate(kfold.split(indices, dataset.label_list)):\n",
    "            index_dict[i] = {'train_index': train_index,\n",
    "                             'test_index': test_index}\n",
    "\n",
    "        with open(kfold_split_index_path, 'wb') as file:\n",
    "            pkl.dump(index_dict, file)\n",
    "    else:\n",
    "        with open(kfold_split_index_path, 'rb') as file:\n",
    "            index_dict = pkl.load(file)\n",
    "\n",
    "    index_split = index_dict[fold]\n",
    "    train_index, test_index = index_split['train_index'], index_split['test_index']\n",
    "\n",
    "    trian_dataset = Subset(dataset, train_index)\n",
    "    test_dataset = Subset(dataset, test_index)\n",
    "\n",
    "    return trian_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels, 128, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "                                    nn.LeakyReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(\n",
    "            128, 64, kernel_size=5, stride=1, padding=2, bias=True), nn.LeakyReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(\n",
    "            64, 32, kernel_size=5, stride=1, padding=2, bias=True), nn.LeakyReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(\n",
    "            32, 16, kernel_size=3, stride=1, padding=1, bias=True), nn.LeakyReLU())\n",
    "        self.delayer1 = nn.Sequential(nn.ConvTranspose2d(16 + 32, 32, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "                                      nn.LeakyReLU())\n",
    "        self.delayer2 = nn.Sequential(nn.ConvTranspose2d(32 + 64, 64, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "                                      nn.LeakyReLU())\n",
    "        self.delayer3 = nn.Sequential(nn.ConvTranspose2d(\n",
    "            64 + 128, 128, kernel_size=3, stride=1, padding=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #         x = channel_to_location(x)\n",
    "        mask = (x.abs().sum(dim=1, keepdim=True) > 0).float()\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        out3 = self.layer3(out2)\n",
    "        out = self.layer4(out3)\n",
    "        out = self.delayer1(torch.cat([out, out3], dim=1))\n",
    "        out = self.delayer2(torch.cat([out, out2], dim=1))\n",
    "        out = self.delayer3(torch.cat([out, out1], dim=1))\n",
    "        return out * mask\n",
    "\n",
    "\n",
    "class ResidualConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "                                  nn.SELU(),\n",
    "                                  nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=bias))\n",
    "        self.res = nn.Conv2d(in_channels, out_channels,\n",
    "                             kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) + self.res(x)\n",
    "\n",
    "\n",
    "class InceptionConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv5x5 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=5, stride=1, padding=2, bias=bias)\n",
    "        self.conv3x3 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=bias)\n",
    "        self.conv1x1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv5x5(x) + self.conv3x3(x) + self.conv1x1(x)\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.depth = nn.Conv2d(in_channels,\n",
    "                               in_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=stride,\n",
    "                               padding=padding,\n",
    "                               groups=in_channels,\n",
    "                               bias=bias)\n",
    "        self.point = nn.Conv2d(in_channels, out_channels,\n",
    "                               kernel_size=1, stride=stride, padding=0, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depth(x)\n",
    "        x = self.point(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=4):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels,\n",
    "                                256,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=1,\n",
    "                                bias=True)\n",
    "        self.layer2 = nn.Conv2d(256,\n",
    "                                128,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer3 = nn.Conv2d(128,\n",
    "                                64,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer4 = nn.Conv2d(64,\n",
    "                                32,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "        self.layer5 = nn.Conv2d(32,\n",
    "                                16,\n",
    "                                kernel_size=5,\n",
    "                                stride=1,\n",
    "                                padding=2,\n",
    "                                bias=True)\n",
    "\n",
    "        self.drop = nn.Sequential(nn.SELU())\n",
    "        self.fc1 = nn.Sequential(nn.Linear(9 * 9 * 16, 1024, bias=True),\n",
    "                                 nn.SELU())\n",
    "        self.fc2 = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.drop(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=4):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(\n",
    "            in_channels, 256, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.layer2 = nn.Conv2d(256, 128, kernel_size=5,\n",
    "                                stride=1, padding=2, bias=True)\n",
    "        self.layer3 = nn.Conv2d(128, 64, kernel_size=5,\n",
    "                                stride=1, padding=2, bias=True)\n",
    "        self.layer4 = SeparableConv2d(\n",
    "            64, 32, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.layer5 = InceptionConv2d(32, 16)\n",
    "        self.drop = nn.Sequential(nn.Dropout(), nn.SELU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(9 * 9 * 16, 1024, bias=True), nn.SELU())\n",
    "        self.fc2 = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.drop(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        feat = self.fc1(out)\n",
    "        out = self.fc2(feat)\n",
    "        return out, feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = Generator(in_channels=CFG.TIMESTEP_NUM, out_channels=CFG.TIMESTEP_NUM)\n",
    "d_model = Discriminator(num_classes=1, in_channels=CFG.TIMESTEP_NUM)\n",
    "c_model = Classifier(num_classes=CFG.NUM_CLASSES, in_channels=CFG.TIMESTEP_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dicts = torch.load('sslgan_raw2raw_wo_classifier.pt')\n",
    "gan_state_dicts = torch.load('./parameters/cross_validation_proposed_woconv_pretrain.pth')\n",
    "\n",
    "g_model.load_state_dict(gan_state_dicts['g_model'])\n",
    "d_model.load_state_dict(gan_state_dicts['d_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c_model.load_state_dict(torch.load(\n",
    "#     'cross_validation_finetune' + str(CFG.FOLD) + '.pth')['c_model'])\n",
    "c_model.load_state_dict(torch.load(\n",
    "    './parameters/cross_validation_backbone_arousal' + str(CFG.FOLD) + '.pth')['c_model'])\n",
    "# c_model.load_state_dict(gan_state_dicts['c_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask(data):\n",
    "    # batch_size*channel_num*time_step\n",
    "    data = data.clone()\n",
    "    mask = torch.rand(\n",
    "        *data.shape[:2], *([1] * (len(data.shape) - 2)), device=data.device)\n",
    "    ratio = np.random.beta(1.0, 1.0, size=(data.shape[0], 1, 1, 1))\n",
    "    ratio = torch.tensor(ratio, device=mask.device).clamp(max=0.5)\n",
    "    mask = mask < ratio\n",
    "    mask = mask.expand_as(data)\n",
    "    data[mask] = 0.0\n",
    "    return data, ratio\n",
    "\n",
    "\n",
    "def extract_feature(dataloader):\n",
    "    extracted_features_list = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(CFG.DEVICE)\n",
    "\n",
    "#             aug_x, ratio = random_mask(x)\n",
    "#             aug_x = g_model(aug_x).detach()\n",
    "#             aug_y_hat, aug_x_feat = c_model(aug_x)\n",
    "\n",
    "            y_hat, x_feat = c_model(x)\n",
    "\n",
    "            extracted_features = x_feat.detach().cpu().numpy()\n",
    "            extracted_features_list.append(extracted_features)\n",
    "\n",
    "    extracted_features_list = np.concatenate(extracted_features_list)\n",
    "    return extracted_features_list\n",
    "\n",
    "\n",
    "def extract_gan_feature(dataloader):\n",
    "    extracted_features_list = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(CFG.DEVICE)\n",
    "\n",
    "            aug_x, ratio = random_mask(x)\n",
    "            aug_x = g_model(aug_x).detach()\n",
    "#             aug_x = g_model(x).detach()\n",
    "\n",
    "            y_hat, x_feat = c_model(aug_x)\n",
    "\n",
    "            extracted_features = x_feat.detach().cpu().numpy()\n",
    "            extracted_features_list.append(extracted_features)\n",
    "\n",
    "    extracted_features_list = np.concatenate(extracted_features_list)\n",
    "    return extracted_features_list\n",
    "\n",
    "\n",
    "def calculate_feature_statistics(extract_features):\n",
    "    \"\"\"Calculates the statistics used by FID\n",
    "    Args:\n",
    "        images: torch.tensor, shape: (N, 3, H, W), dtype: torch.float32 in range 0 - 1\n",
    "        batch_size: batch size to use to calculate inception scores\n",
    "    Returns:\n",
    "        mu:     mean over all activations from the last pool layer of the inception model\n",
    "        sigma:  covariance matrix over all activations from the last pool layer \n",
    "                of the inception model.\n",
    "    \"\"\"\n",
    "    mu = np.mean(extract_features, axis=0)\n",
    "    sigma = np.cov(extract_features, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "# calculate_feature_statistics(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n",
    "    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "    # product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n",
    "        warnings.warn(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError(\"Imaginary component {}\".format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "\n",
    "\n",
    "def calculate_fid(dataloader):\n",
    "    \"\"\" Calculate FID between images1 and images2\n",
    "    Args:\n",
    "        images1: np.array, shape: (N, H, W, 3), dtype: np.float32 between 0-1 or np.uint8\n",
    "        images2: np.array, shape: (N, H, W, 3), dtype: np.float32 between 0-1 or np.uint8\n",
    "        use_multiprocessing: If multiprocessing should be used to pre-process the images\n",
    "        batch size: batch size used for inception network\n",
    "    Returns:\n",
    "        FID (scalar)\n",
    "    \"\"\"\n",
    "    gt_features = extract_feature(dataloader)\n",
    "    gan_features = extract_gan_feature(dataloader)\n",
    "\n",
    "    gt_mu1, gt_sigma1 = calculate_feature_statistics(gt_features)\n",
    "    gan_mu2, gan_sigma2 = calculate_feature_statistics(gan_features)\n",
    "\n",
    "    fid = calculate_frechet_distance(gt_mu1, gt_sigma1, gan_mu2, gan_sigma2)\n",
    "    return fid\n",
    "\n",
    "# calculate_fid(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "\n",
    "eeg_dataset = EEGDataset(preprocessors_results,\n",
    "                                 feature_key='feature',\n",
    "                                 label_key='label')\n",
    "train_dataset, val_dataset = train_test_split(eeg_dataset, fold=CFG.FOLD)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=CFG.BATCH_SIZE,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286.63298911456275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model = g_model.to(CFG.DEVICE)\n",
    "d_model = d_model.to(CFG.DEVICE)\n",
    "c_model = c_model.to(CFG.DEVICE)\n",
    "\n",
    "calculate_fid(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
